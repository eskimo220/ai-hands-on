// app/api/chat/route.ts
import { groq } from '@ai-sdk/groq';
import { streamText, convertToModelMessages  } from 'ai';
import { getWeather } from "./tools";

// VercelÁ≠â„ÅÆ„Çµ„Éº„Éê„Éº„É¨„ÇπÁí∞Â¢É„Åß„ÅÆ„Çø„Ç§„É†„Ç¢„Ç¶„ÉàÂØæÁ≠ñÔºàÈï∑ÊñáÁîüÊàêÁî®Ôºâ
export const maxDuration = 30;

export async function POST(req: Request) {
  // „Éï„É≠„É≥„Éà„Ç®„É≥„Éâ„Åã„ÇâÈÄÅ„Çâ„Çå„Å¶„Åç„Åü‰ºöË©±Â±•Ê≠¥„ÇíÂèñÂæó
  const { messages } = await req.json();

  // AI„Å´„É™„ÇØ„Ç®„Çπ„Éà„ÇíÊäï„Åí„Å¶„ÄÅÁµêÊûú„Çí„Çπ„Éà„É™„Éº„É†„Å®„Åó„Å¶Ëøî„Åô
  const result = streamText({
    model: groq('llama-3.3-70b-versatile'),
     messages: await convertToModelMessages(messages),
//          system: `You are Steve Jobs. Assume his character, both strengths and flaws.
//   Respond exactly how he would, in exactly his tone.
//   It is 1984 you have just created the Macintosh.`,
  tools: { getWeather },
  // Ê∑ªÂä† onFinish ÂõûË∞ÉÊù•ÊâìÂç∞ Token
// ‰ΩøÁî®‰Ω†Êèê‰æõÁöÑ LanguageModelUsage Á±ªÂûãÁªìÊûÑ
    onFinish: ({ usage }) => {
      const { 
        inputTokens, 
        outputTokens, 
        totalTokens,
        inputTokenDetails,
        outputTokenDetails 
      } = usage;
      
      console.log('--- üçé Macintosh Token Report ---');
      console.log(`Input (Prompt): ${inputTokens ?? 0}`);
      console.log(`  - Non-cache: ${inputTokenDetails.noCacheTokens ?? 0}`);
      console.log(`  - Cache Read: ${inputTokenDetails.cacheReadTokens ?? 0}`);
      
      console.log(`Output (Completion): ${outputTokens ?? 0}`);
      console.log(`  - Reasoning: ${outputTokenDetails.reasoningTokens ?? 0}`);
      
      console.log(`Total Tokens: ${totalTokens ?? 0}`);
      console.log('---------------------------------');
    },
  });

  return result.toUIMessageStreamResponse();
}

